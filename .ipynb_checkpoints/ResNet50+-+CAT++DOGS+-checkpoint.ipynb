{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc/data_cd/redux/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "%cd $DATA_HOME_DIR/train\n",
    "\n",
    "%pwd\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000): os.rename(shuf[i], DATA_HOME_DIR+'/valid' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data_cd/redux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc/data_cd/redux\n"
     ]
    }
   ],
   "source": [
    "#Create directories\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\\\n",
    "    \n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc/data_cd/redux/sample/train\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/wbc/data_cd/redux/sample/valid\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/wbc/data_cd/redux/valid\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/wbc/data_cd/redux/train\n"
     ]
    }
   ],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd /home/ubuntu/wbc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Loaded\n"
     ]
    }
   ],
   "source": [
    "#Allow relative imports to directories above lesson1/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "#import modules\n",
    "from utils import *\n",
    "from resnet50 import Resnet50\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline\n",
    "print (\"Library Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc/data_cd/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = '/home/ubuntu/wbc/data_cd/redux/test/'\n",
    " #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path='/home/ubuntu/wbc/data_cd/redux/train'\n",
    "valid_path='/home/ubuntu/wbc/data_cd/redux/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    }
   ],
   "source": [
    "resnet=Resnet50(include_top=False).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size=64\n",
    "no_of_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 7, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune the model\n",
    "batches = get_batches(train_path,shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(valid_path, batch_size=batch_size*2,shuffle=False)\n",
    "\n",
    "(val_classes,trn_classes,val_labels,trn_labels,val_filenames,\n",
    "filenames,test_filenames)=get_classes(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_features=resnet.predict_generator(val_batches,val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "save_array(results_path+\"val_resnet_conv.bc\",val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features=resnet.predict_generator(batches,batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save_array(results_path+\"trn_resnet_conv.bc\",trn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_fc_layers(p):\n",
    "    return [\n",
    "        BatchNormalization(axis=1,input_shape=resnet.output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(1024,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(1024,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(2,activation='softmax')\n",
    "        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential(get_fc_layers(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/2\n",
      "  512/23000 [..............................] - ETA: 651s - loss: 0.0078 - acc: 0.9980"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-fa042b300e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrn_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(trn_features,trn_labels,nb_epoch=2,batch_size=batch_size,validation_data=(val_features,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ap_layers(p):\n",
    "    return [\n",
    "        GlobalAveragePooling2D(input_shape=resnet.output_shape[1:]),\n",
    "        Dropout(p),\n",
    "        Dense(2,activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential(get_ap_layers(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0208 - acc: 0.9926 - val_loss: 0.0386 - val_acc: 0.9860\n",
      "Epoch 2/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0318 - val_acc: 0.9915\n",
      "Epoch 3/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0334 - val_acc: 0.9905\n",
      "Epoch 4/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0163 - acc: 0.9950 - val_loss: 0.0371 - val_acc: 0.9905\n",
      "Epoch 5/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0351 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0376 - val_acc: 0.9905\n",
      "Epoch 7/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0439 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0440 - val_acc: 0.9880\n",
      "Epoch 9/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0368 - val_acc: 0.9910\n",
      "Epoch 10/10\n",
      "23000/23000 [==============================] - 7s - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0383 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b0d6aee10>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trn_features,trn_labels,nb_epoch=10,batch_size=100,\n",
    "          validation_data=(val_features,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(test_path, batch_size=batch_size*2,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features=resnet.predict_generator(test_batches,test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=model1.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array(results_path + 'test_preds.dat', pred)\n",
    "save_array(results_path + 'filenames.dat', test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Predictions: [  9.9972e-01   9.5801e-01   1.0000e+00   1.8859e-08   7.7649e-03]\n",
      "Mid Predictions: [ 0.4089  0.5134  0.5006  0.5247  0.5787  0.5057  0.4407  0.4047  0.548   0.4744  0.5096  0.4888\n",
      "  0.5402  0.5035  0.4622  0.5019  0.4981  0.5696  0.4702  0.4838  0.5186  0.5057  0.5118  0.5988\n",
      "  0.5227  0.4416  0.4943  0.4681  0.5519  0.5573  0.5747  0.4419  0.5113  0.4193  0.4986  0.4877\n",
      "  0.5214  0.5354  0.5822  0.4966  0.4766  0.4206  0.585   0.4896  0.4127  0.5711  0.4773  0.5889\n",
      "  0.4918  0.4569  0.5277  0.5929]\n",
      "Edge Predictions: [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = pred[:,1]\n",
    "print (\"Raw Predictions: \" + str(isdog[:5]))\n",
    "print (\"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)]))\n",
    "print (\"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So to play it safe, we use a sneaky trick to round down our edge predictions\n",
    "#Swap all ones with .95 and all zeros with .05\n",
    "isdog = isdog.clip(min=0.05, max=0.95)\n",
    "pred = load_array(results_path + 'test_preds.dat')\n",
    "T_filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unknown/377.jpg', 'unknown/17.jpg', 'unknown/2452.jpg', ..., 'unknown/2093.jpg',\n",
       "       'unknown/9990.jpg', 'unknown/1619.jpg'], \n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 377   17 2452 ..., 2093 9990 1619]\n"
     ]
    }
   ],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "#filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in T_filenames])\n",
    "print (ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.7700e+02,   9.5000e-01],\n",
       "       [  1.7000e+01,   9.5000e-01],\n",
       "       [  2.4520e+03,   9.5000e-01],\n",
       "       [  1.1565e+04,   5.0000e-02],\n",
       "       [  2.0430e+03,   5.0000e-02]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc/data_cd/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission18.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/wbc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='data_cd/redux/submission18.csv' target='_blank'>data_cd/redux/submission18.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/wbc/data_cd/redux/submission18.csv"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('data_cd/redux/'+submission_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Check and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=model1.predict(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenamesa = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = prob[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + filenamesa[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1981 correct labels\n"
     ]
    }
   ],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print (\"Found %d correct labels\" % len(correct))\n",
    "idx = permutation(correct)[:n_view]\n",
    "#plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 incorrect labels\n"
     ]
    }
   ],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "#plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 996 confident correct cats labels\n"
     ]
    }
   ],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print (\"Found %d confident correct cats labels\" % len(correct_cats))\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "#plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 985 confident correct dogs labels\n"
     ]
    }
   ],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print (\"Found %d confident correct dogs labels\" % len(correct_dogs))\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "#plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 incorrect cats\n"
     ]
    }
   ],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print (\"Found %d incorrect cats\" % len(incorrect_cats))\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "   # plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 incorrect dogs\n"
     ]
    }
   ],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print (\"Found %d incorrect dogs\" % len(incorrect_dogs))\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    #plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[996   8]\n",
      " [ 11 985]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[997   7]\n",
      " [ 10 986]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEmCAYAAAA0k8gFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9abaaafcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
